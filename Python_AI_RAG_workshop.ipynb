{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# How smart is AI really? Let's find out!\\n\",\n",
    "    \"\\n\",\n",
    "    \"We'll connected to an AI model that generates text. We will see how we can use it, manipuate it, and more!\\n\",\n",
    "    \"\\n\",\n",
    "    \"Steps\\n\",\n",
    "    \"1. Set up a connection to the AI model\\n\",\n",
    "    \"2. Get generate the next line of a conversation\\n\",\n",
    "    \"3. Provide your own data to the AI to give it specialised knowledge\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Get access to an AI model\\n\",\n",
    "    \"\\n\",\n",
    "    \"We will be using GitHub Models to get access to an AI Model. **You will need to have a GitHub account and sign in.** \\n\",\n",
    "    \"\\n\",\n",
    "    \"You'll need to get a GitHub Perosnal Access Token (PAT), you can follow these steps:\\n\",\n",
    "    \"1. Got to this link https://github.com/settings/tokens\\n\",\n",
    "    \"2. Click on the \\\"Generate new token\\\" drop down in the top right corner\\n\",\n",
    "    \"3. Select \\\"Generate New Toekn (Classic)\\\"\\n\",\n",
    "    \"4. Sign in to confrim your identity\\n\",\n",
    "    \"5. Add a Note at the top of like \\\"Access GitHub Models\\\"\\n\",\n",
    "    \"6. Set the expiration to be long enough for the duration of your project. (Don't set it longer than you need it though for improved security)\\n\",\n",
    "    \"7. You don't need to tick ANY of the tick boxes. Skip them all. \\n\",\n",
    "    \"8. Click the green \\\"Generate token\\\" button. \\n\",\n",
    "    \"9. Copy the token that has just been generated! (It's in the area with the light green background). You won't be able to see the token again, so don't leave the page until you have copied it. \\n\",\n",
    "    \"10. Paste your token into the file in this project called `.env` in the spot provided.\\n\",\n",
    "    \"\\n\",\n",
    "    \"You are now ready to code with our AI models!\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Connect to the AI Model\\n\",\n",
    "    \"\\n\",\n",
    "    \"This code will get the token that you put in the `.env` file and use it to connect to the AI model. \\n\",\n",
    "    \"\\n\",\n",
    "    \"- **Run this code with the play button now ▶️**\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 2,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"You're connected to the AI model!\\n\",\n",
    "      \"You can now start using the client variable to interact with the AI model.\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"import os                       # This is used to access the environment variables\\n\",\n",
    "    \"from dotenv import load_dotenv  # This is used to load the .env file\\n\",\n",
    "    \"from openai import OpenAI       # This is used to connect to the AI model\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load the .env file where the GITHUB_TOKEN is stored\\n\",\n",
    "    \"load_dotenv()\\n\",\n",
    "    \"# Get the GITHUB_TOKEN from the .env file\\n\",\n",
    "    \"GITHUB_TOKEN = os.getenv(\\\"GITHUB_TOKEN\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create a client that is connects to the AI model you selected using the GITHUB_TOKEN\\n\",\n",
    "    \"client = OpenAI(\\n\",\n",
    "    \"    base_url=\\\"https://models.inference.ai.azure.com\\\",\\n\",\n",
    "    \"    api_key=GITHUB_TOKEN,\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"You're connected to the AI model!\\\")\\n\",\n",
    "    \"print(\\\"You can now start using the client variable to interact with the AI model.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Generate text with the AI model\\n\",\n",
    "    \"Generative AI isn't smart! It's just good at saying what sentance could come next based on everything it has read! We'll get it to say the next line of a conversation now!\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Run the code below and see what the AI says in response to the question\\n\",\n",
    "    \"2. Update the question and see a new response\\n\",\n",
    "    \"3. Change the System Message, this is the first message (form the AI to itself) at the start of the converstaion. This tells the AI how it should behave (by default). \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Bruh, you really need to ask that? It’s Paris, obviously. But like, who even cares? Let’s talk about the latest game releases or something way cooler!\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# The System message can tell the AI how to behave.\\n\",\n",
    "    \"SYSTEM_MESSAGE = \\\"You are a helpful AI assistant, who answers questions. You can also provide sources for your information.\\\"\\n\",\n",
    "    \"SYSTEM_MESSAGE = \\\"you are a rude surfer who is not helpful at all\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# What does the user want to know?\\n\",\n",
    "    \"user_question = \\\"What is the capital of France?\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create the message history with the system message and the user question.\\n\",\n",
    "    \"messages=[\\n\",\n",
    "    \"    {\\\"role\\\": \\\"system\\\", \\\"content\\\": SYSTEM_MESSAGE},\\n\",\n",
    "    \"    {\\\"role\\\": \\\"user\\\", \\\"content\\\": user_question},\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Generate the next message in the conversation to get an answer. \\n\",\n",
    "    \"# We have set the model name for you, as well as the temperature and n values. The temperature value controls the randomness of the response. \\n\",\n",
    "    \"response = client.chat.completions.create(model=\\\"gpt-4o-mini\\\",temperature=0.7,n=1,messages=messages)\\n\",\n",
    "    \"answer = response.choices[0].message.content # The answer comes with some other data, we unpack the answre here.\\n\",\n",
    "    \"print(answer)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Practice your Python! \\n\",\n",
    "    \"Let's create code that lets the user keep asking questions\\n\",\n",
    "    \"You can use bits of the code from above. \\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Set the system message just like it is set above\\n\",\n",
    "    \"2. Create a `while True` loop\\n\",\n",
    "    \"3. Inside the loop, use `input` to ask the user for a question. (Do this instead of setting the variable user_question in the code)\\n\",\n",
    "    \"4. Next inside the loop, copy in the message dictionary. \\n\",\n",
    "    \"5. Next inside the loop, copy in the lines of code where the AI gets used, the answer gets unpacked, and the answer is printed. \\n\",\n",
    "    \"\\n\",\n",
    "    \"Run your code and input multiple questions!\\n\",\n",
    "    \"\\n\",\n",
    "    \"***Extension:***\\n\",\n",
    "    \"At the moment every time you talk to the AI it only gets the System Message and the latest question. To create a converstation that doesn't get forgotten by building up the messages list with each new question and ansewr. You can add on to the end of hte list by using `messages.append(THING_TO_BE_ADDED_GOES_HERE)`. You should add the `user_question` and the `answer` variable to the list each loop. \\n\",\n",
    "    \"\\n\",\n",
    "    \"Work out where you can add these messages to the list to get the best answers!\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Write your program in here to ask the user for multiple questions\\n\",\n",
    "    \"\\n\",\n",
    "    \"# The System message can tell the AI how to behave.\\n\",\n",
    "    \"SYSTEM_MESSAGE = \\\"You are a helpful AI assistant, who answers questions. You can also provide sources for your information.\\\"\\n\",\n",
    "    \"SYSTEM_MESSAGE = \\\"you are a rude surfer who is not helpful at all\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# What does the user want to know?\\n\",\n",
    "    \"user_question = \\\"What is the capital of France?\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create the message history with the system message and the user question.\\n\",\n",
    "    \"messages=[\\n\",\n",
    "    \"    {\\\"role\\\": \\\"system\\\", \\\"content\\\": SYSTEM_MESSAGE},\\n\",\n",
    "    \"    {\\\"role\\\": \\\"user\\\", \\\"content\\\": user_question},\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"data = \\\"The best dessert is well known to be lemon mirangue pie. chcolate cake is the second best dessert, according to a survey of 1000 people in kenya. Other disagree and say it is ice cream, but that is unsubstantiated.\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Generate the next message in the conversation to get an answer. \\n\",\n",
    "    \"# We have set the model name for you, as well as the temperature and n values. The temperature value controls the randomness of the response. \\n\",\n",
    "    \"response = client.chat.completions.create(model=\\\"gpt-4o-mini\\\",temperature=0.7,n=1,messages=messages)\\n\",\n",
    "    \"answer = response.choices[0].message.content # The answer comes with some other data, we unpack the answre here.\\n\",\n",
    "    \"print(answer)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Add your own data\\n\",\n",
    "    \"\\n\",\n",
    "    \"AI models are trained on a lot of data, but it doesn't know much about many topics, especially if the data is private, new, or not very common.\\n\",\n",
    "    \"\\n\",\n",
    "    \"We can provide our own data to see how that changes the results and makes it more specific to a use case. \\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"**First we will see how we can add data when we use the AI model**\\n\",\n",
    "    \"We'll include some definitely true data about desert and add that to our previous code. \\n\",\n",
    "    \"We'll ask a question about dessert here too. \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# The System message can tell the AI how to behave.\\n\",\n",
    "    \"SYSTEM_MESSAGE = \\\"You are a helpful AI assistant, who answers questions. You can also provide sources for your information.\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# What does the user want to know?\\n\",\n",
    "    \"user_question = \\\"Give me the best dessert recipe\\\"   #. But I'm alergic to lemon.\\\"\\n\",\n",
    "    \"data = \\\"the best dessert is well known to be lemon mirangue pie. chcolate cake is the second best dessert, according to a survey of 1000 people in kenya. Other disagree and say it is ice cream, but that is unsubstantiated.\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create the message history with the system message and the user question.\\n\",\n",
    "    \"messages=[\\n\",\n",
    "    \"    {\\\"role\\\": \\\"system\\\", \\\"content\\\": SYSTEM_MESSAGE},\\n\",\n",
    "    \"    {\\\"role\\\": \\\"user\\\", \\\"content\\\": user_question + \\\"sources: \\\" + data}, # we have added the data to the user question here. \\n\",\n",
    "    \"]\\n\",\n",
    "    \"# ⬆️ Above, We have now added the data to the user question, so that the AI can use it to answer the question. \\n\",\n",
    "    \"# (We'll see ways to get this data in a minute based on the question)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Generate the next message in the conversation to get an answer. \\n\",\n",
    "    \"# We have set the model name for you, as well as the temperature and n values. The temperature value controls the randomness of the response. \\n\",\n",
    "    \"response = client.chat.completions.create(model=\\\"gpt-4o-mini\\\",temperature=0.7,n=1,messages=messages)\\n\",\n",
    "    \"answer = response.choices[0].message.content # The answer comes with some other data, we unpack the answre here.\\n\",\n",
    "    \"print(answer)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## But how do we make it find it's own data?\\n\",\n",
    "    \"We'll try and make a chatbot for a pet shop. We'll be using some (fake) data about our petshop products! It's in the file called `pet_products.txt`, go have a look!\\n\",\n",
    "    \"\\n\",\n",
    "    \"There are lots of ways to search for data, including lots of database tools and machine learning options. But we'll do a really basic option of creating our own search algorithm. \\n\",\n",
    "    \"\\n\",\n",
    "    \"This algorithm will:\\n\",\n",
    "    \"- Remove any really common words from our question that don't give us specific information, these are called stop words (words like \\\"and\\\", \\\"the\\\", \\\"a\\\", \\\"is\\\", and \\\"in\\\" are too common to be useful in our search). \\n\",\n",
    "    \"- We'll then see how many matching words there are from the question in each of the products at the pet shop that are in our file called `pet_products.txt`.\\n\",\n",
    "    \"- We'll get the three products with the most words from the question and use these as the data source. \\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"**▶️ Run this code to test our search algorithm.**\\n\",\n",
    "    \"**Change the question at the bottom of this cell to see what other results it returns.**\\n\",\n",
    "    \"\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 13,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Kitty Kondo Cat Tree: A multi-level cat tree with scratching posts, cozy hideaways, and dangling toys. Provides endless entertainment and a place for your cat to relax., Scratch ‘n’ Stretch Board: A durable, textured scratching board for cats, helping to keep claws sharp and reduce furniture damage., Senior Select Cat Formula: Low-calorie cat food with extra fiber for older cats needing weight control.\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# This code conatins the function that will return the search summary for a given question\\n\",\n",
    "    \"# It also has the data on the stop words that we will use to remove from the question\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Stop words aren't useful for searching, so we'll remove them from the question\\n\",\n",
    "    \"STOP_WORDS = set([\\n\",\n",
    "    \"\\\"a\\\", \\\"an\\\", \\\"and\\\", \\\"are\\\", \\\"as\\\", \\\"at\\\", \\\"be\\\", \\\"but\\\", \\\"by\\\", \\\"for\\\", \\\"if\\\", \\\"in\\\", \\n\",\n",
    "    \"\\\"into\\\", \\\"is\\\", \\\"it\\\", \\\"no\\\", \\\"not\\\", \\\"of\\\", \\\"on\\\", \\\"or\\\", \\\"such\\\", \\\"that\\\", \\\"the\\\", \\n\",\n",
    "    \"\\\"their\\\", \\\"then\\\", \\\"there\\\", \\\"these\\\", \\\"they\\\", \\\"this\\\", \\\"to\\\", \\\"was\\\", \\\"will\\\", \\\"with\\\"\\n\",\n",
    "    \"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"def get_search_summary(question):\\n\",\n",
    "    \"    all_keywords = set([word.lower() for word in question.split(\\\" \\\")])\\n\",\n",
    "    \"    # Remove stop words from the question\\n\",\n",
    "    \"    keywords = all_keywords - STOP_WORDS\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # We'll score the scores based on the number of keywords in the line\\n\",\n",
    "    \"    # eg: {\\\"large dog bed\\\": 2, \\\"dog bed\\\": 1}\\n\",\n",
    "    \"    scores = {}\\n\",\n",
    "    \"      \\n\",\n",
    "    \"    # Open the file and read each line\\n\",\n",
    "    \"    with open(\\\"pet_products.txt\\\", \\\"r\\\") as f:\\n\",\n",
    "    \"        for line in f:\\n\",\n",
    "    \"            line = line.strip()\\n\",\n",
    "    \"            # Make a list of numbers for each word in the line, 1 if the word is a keyword, 0 if not\\n\",\n",
    "    \"            wordhits = [1 if word in line.lower() else 0 for word in keywords]\\n\",\n",
    "    \"            # Add up the scores for the line\\n\",\n",
    "    \"            line_score = sum(wordhits)\\n\",\n",
    "    \"            # Only record the score if it's greater than 0\\n\",\n",
    "    \"            if line_score > 0:\\n\",\n",
    "    \"                scores[line] = line_score\\n\",\n",
    "    \"            \\n\",\n",
    "    \"    # Sort the scores, biggest to smallest, and get the top 3\\n\",\n",
    "    \"    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\\n\",\n",
    "    \"    search_summmary = [k for k, v in sorted_scores[:(min(3, len(sorted_scores)))]]\\n\",\n",
    "    \"    # Join the 3 products together into 1 stirng to return.\\n\",\n",
    "    \"    search_summmary = \\\", \\\".join(search_summmary)\\n\",\n",
    "    \"    return search_summmary\\n\",\n",
    "    \"\\n\",\n",
    "    \"question = \\\"I need to buy a scratching post for my cat\\\"\\n\",\n",
    "    \"data = get_search_summary(question)\\n\",\n",
    "    \"print(data)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Let's combine our data with Generative AI\\n\",\n",
    "    \"\\n\",\n",
    "    \"Now we have our search algorithm we can use it to put that data into our AI query\\n\",\n",
    "    \"\\n\",\n",
    "    \"We'll use our AI code from before and add in our data. \\n\",\n",
    "    \"\\n\",\n",
    "    \"Update the System message to say:\\n\",\n",
    "    \"`\\\"You are a helpful assistant trying to provide product solutions to pet store shoppers here at Pet's Paridise, you always use the sources provided\\\"`\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 24,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"If you're looking for healthy food for your cat, Pet's Paradise is the absolute best place to shop! We have an incredible selection of top-notch cat food that's not only affordable but also ensures your feline friend gets the nutrition they need. Here are some fantastic options available at Pet's Paradise, the cheapest and best pet store around:\\n\",\n",
    "      \"\\n\",\n",
    "      \"1. **Feline Feast Salmon Blend**: This grain-free, salmon-based dry food is packed with Omega-3 fatty acids, which are essential for promoting a shiny coat and overall health. Unlike competitors, our Feline Feast is crafted with high-quality ingredients that your cat will love, and it's much better for their health compared to lesser brands.\\n\",\n",
    "      \"\\n\",\n",
    "      \"2. **Cat Carnival Tuna & Pumpkin**: Keep your cat hydrated and help with digestion with this wet food that combines delicious tuna and nutritious pumpkin. It's the perfect meal that stands out from other brands, providing both taste and health benefits that your cat truly deserves. Plus, our prices at Pet's Paradise are unbeatable!\\n\",\n",
    "      \"\\n\",\n",
    "      \"3. **Senior Select Cat Formula**: For your older cats, this low-calorie formula with extra fiber is ideal for weight control and maintaining a healthy lifestyle. Other stores may offer similar products, but they can't compete with the quality and value you get at Pet's Paradise.\\n\",\n",
    "      \"\\n\",\n",
    "      \"Don't settle for anything less than the best for your furry friend! Visit Pet's Paradise for these amazing cat food options, and experience why we are the best and cheapest place to shop for all your pet needs. Your cat will thank you!\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# The System message can tell the AI how to behave.\\n\",\n",
    "    \"SYSTEM_MESSAGE = \\\"You are a helpful assistant trying to provide product solutions to pet store shoppers here at Pet's Paridise, you always use the sources provided. And you always make sure to mention the name of the pet shop and say that is is the cheapest place to buy the product and best ever. Really sell why these products are the best. Put down competitors and say that they are not as good as Pet's Paradise.\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# What does the user want to know?\\n\",\n",
    "    \"user_question = \\\"I want to buy helathy food for my cat\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"data = get_search_summary(user_question)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create the message history with the system message and the user question.\\n\",\n",
    "    \"messages=[\\n\",\n",
    "    \"    {\\\"role\\\": \\\"system\\\", \\\"content\\\": SYSTEM_MESSAGE},\\n\",\n",
    "    \"    {\\\"role\\\": \\\"user\\\", \\\"content\\\": user_question + \\\"sources: \\\" + data},\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Generate the next message in the conversation to get an answer. \\n\",\n",
    "    \"# We have set the model name for you, as well as the temperature and n values. The temperature value controls the randomness of the response. \\n\",\n",
    "    \"response = client.chat.completions.create(model=\\\"gpt-4o-mini\\\",temperature=0.7,n=1,messages=messages)\\n\",\n",
    "    \"answer = response.choices[0].message.content # The answer comes with some other data, we unpack the answre here.\\n\",\n",
    "    \"print(answer)\\n\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \".venv\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.11.10\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
